{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAmUD1eZHryf"
      },
      "source": [
        "# **Word vectors**\n",
        "\n",
        "\n",
        "In the previous exercise we observed that colors that we think of as similar are 'closer' to each other in RGB vector space. Is it possible to create a vector space for all English words that has this same 'closer in space is closer in meaning' property?\n",
        "\n",
        "The answer is yes! Luckily, you don't need to create those vectors from scratch. Many researchers have made downloadable databases of pre-trained vectors. One such project is [Stanford's Global Vectors for Word Representation (GloVe)](https://nlp.stanford.edu/projects/glove/).\n",
        "\n",
        "These $300$-dimensional vectors are included with $\\texttt{spaCy}$, and they're the vectors we'll be using in this exercise.\n",
        "\n",
        "![cosine similarity: picture](https://d33wubrfki0l68.cloudfront.net/d2742976a92aa4d6c39f19c747ec5f56ed1cec30/3803f/images/guide-to-word-vectors-with-gensim-and-keras_files/word2vec-king-queen-vectors.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymHr8XZIHsML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d454681-a85e-49c5-b055-b111ecf80e49"
      },
      "source": [
        "# The following will download the language model.\n",
        "# Resart the runtime (Runtime -> Restart runtime) after running this cell\n",
        "# (and don't run it for the second time).\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-01 20:07:40.772640: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-01 20:07:41.575815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb7yqHuGJ6e5"
      },
      "source": [
        "Let's load the model now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-8rsSkSBU8C"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNf5FAkm3Ljj"
      },
      "source": [
        "## **Word vectors: the first glance**\n",
        "\n",
        "You can see the vector of any word in $\\texttt{spaCy}$' s vocabulary using the $\\texttt{vector}$ attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx-IzWxQAgNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c7c62d-a118-4f23-b510-66ca0ab92fe9"
      },
      "source": [
        "# A 300-dimensional vector\n",
        "len(nlp('dog').vector)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8UP3QrxKZPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4d7582-d716-4c71-de1c-b1b84af75e3e"
      },
      "source": [
        "nlp('dog').vector"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.2330e+00,  4.2963e+00, -7.9738e+00, -1.0121e+01,  1.8207e+00,\n",
              "        1.4098e+00, -4.5180e+00, -5.2261e+00, -2.9157e-01,  9.5234e-01,\n",
              "        6.9880e+00,  5.0637e+00, -5.5726e-03,  3.3395e+00,  6.4596e+00,\n",
              "       -6.3742e+00,  3.9045e-02, -3.9855e+00,  1.2085e+00, -1.3186e+00,\n",
              "       -4.8886e+00,  3.7066e+00, -2.8281e+00, -3.5447e+00,  7.6888e-01,\n",
              "        1.5016e+00, -4.3632e+00,  8.6480e+00, -5.9286e+00, -1.3055e+00,\n",
              "        8.3870e-01,  9.0137e-01, -1.7843e+00, -1.0148e+00,  2.7300e+00,\n",
              "       -6.9039e+00,  8.0413e-01,  7.4880e+00,  6.1078e+00, -4.2130e+00,\n",
              "       -1.5384e-01, -5.4995e+00,  1.0896e+01,  3.9278e+00, -1.3601e-01,\n",
              "        7.7732e-02,  3.2218e+00, -5.8777e+00,  6.1359e-01, -2.4287e+00,\n",
              "        6.2820e+00,  1.3461e+01,  4.3236e+00,  2.4266e+00, -2.6512e+00,\n",
              "        1.1577e+00,  5.0848e+00, -1.7058e+00,  3.3824e+00,  3.2850e+00,\n",
              "        1.0969e+00, -8.3711e+00, -1.5554e+00,  2.0296e+00, -2.6796e+00,\n",
              "       -6.9195e+00, -2.3386e+00, -1.9916e+00, -3.0450e+00,  2.4890e+00,\n",
              "        7.3247e+00,  1.3364e+00,  2.3828e-01,  8.4388e-02,  3.1480e+00,\n",
              "       -1.1128e+00, -3.5598e+00, -1.2115e-01, -2.0357e+00, -3.2731e+00,\n",
              "       -7.7205e+00,  4.0948e+00, -2.0732e+00,  2.0833e+00, -2.2803e+00,\n",
              "       -4.9850e+00,  9.7667e+00,  6.1779e+00, -1.0352e+01, -2.2268e+00,\n",
              "        2.5765e+00, -5.7440e+00,  5.5564e+00, -5.2735e+00,  3.0004e+00,\n",
              "       -4.2512e+00, -1.5682e+00,  2.2698e+00,  1.0491e+00, -9.0486e+00,\n",
              "        4.2936e+00,  1.8709e+00,  5.1985e+00, -1.3153e+00,  6.5224e+00,\n",
              "        4.0113e-01, -1.2583e+01,  3.6534e+00, -2.0961e+00,  1.0022e+00,\n",
              "       -1.7873e+00, -4.2555e+00,  7.7471e+00,  1.0173e+00,  3.1626e+00,\n",
              "        2.3558e+00,  3.3589e-01, -4.4178e+00,  5.0584e+00, -2.4118e+00,\n",
              "       -2.7445e+00,  3.4170e+00, -1.1574e+01, -2.6568e+00, -3.6933e+00,\n",
              "       -2.0398e+00,  5.0976e+00,  6.5249e+00,  3.3573e+00,  9.5334e-01,\n",
              "       -9.4430e-01, -9.4395e+00,  2.7867e+00, -1.7549e+00,  1.7287e+00,\n",
              "        3.4942e+00, -1.6883e+00, -3.5771e+00, -1.9013e+00,  2.2239e+00,\n",
              "       -5.4335e+00, -6.5724e+00, -6.7228e-01, -1.9748e+00, -3.1080e+00,\n",
              "       -1.8570e+00,  9.9496e-01,  8.9135e-01, -4.4254e+00,  3.3125e-01,\n",
              "        5.8815e+00,  1.9384e+00,  5.7294e-01, -2.8830e+00,  3.8087e+00,\n",
              "       -1.3095e+00,  5.9208e+00,  3.3620e+00,  3.3571e+00, -3.8807e-01,\n",
              "        9.0022e-01, -5.5742e+00, -4.2939e+00,  1.4992e+00, -4.7080e+00,\n",
              "       -2.9402e+00, -1.2259e+00,  3.0980e-01,  1.8858e+00, -1.9867e+00,\n",
              "       -2.3554e-01, -5.4535e-01, -2.1387e-01,  2.4797e+00,  5.9710e+00,\n",
              "       -7.1249e+00,  1.6257e+00, -1.5241e+00,  7.5974e-01,  1.4312e+00,\n",
              "        2.3641e+00, -3.5566e+00,  9.2066e-01,  4.4934e-01, -1.3233e+00,\n",
              "        3.1733e+00, -4.7059e+00, -1.2090e+01, -3.9241e-01, -6.8457e-01,\n",
              "       -3.6789e+00,  6.6279e+00, -2.9937e+00, -3.8361e+00,  1.3868e+00,\n",
              "       -4.9002e+00, -2.4299e+00,  6.4312e+00,  2.5056e+00, -4.5080e+00,\n",
              "       -5.1278e+00, -1.5585e+00, -3.0226e+00, -8.6811e-01, -1.1538e+00,\n",
              "       -1.0022e+00, -9.1651e-01, -4.7810e-01, -1.6084e+00, -2.7307e+00,\n",
              "        3.7080e+00,  7.7423e-01, -1.1085e+00, -6.8755e-01, -8.2901e+00,\n",
              "        3.2405e+00, -1.6108e-01, -6.2837e-01, -5.5960e+00, -4.4865e+00,\n",
              "        4.0115e-01, -3.7063e+00, -2.1704e+00,  4.0789e+00, -1.7973e+00,\n",
              "        8.9538e+00,  8.9421e-01, -4.8128e+00,  4.5367e+00, -3.2579e-01,\n",
              "       -5.2344e+00, -3.9766e+00, -2.1979e+00,  3.5699e+00,  1.4982e+00,\n",
              "        6.0972e+00, -1.9704e+00,  4.6522e+00, -3.7734e-01,  3.9101e-02,\n",
              "        2.5361e+00, -1.8096e+00,  8.7035e+00, -8.6372e+00, -3.5257e+00,\n",
              "        3.1034e+00,  3.2635e+00,  4.5437e+00, -5.7290e+00, -2.9141e-01,\n",
              "       -2.0011e+00,  8.5328e+00, -4.5064e+00, -4.8276e+00, -1.1786e+01,\n",
              "        3.5607e-01, -5.7115e+00,  6.3122e+00, -3.6650e+00,  3.3597e-01,\n",
              "        2.5017e+00, -3.5025e+00, -3.7891e+00, -3.1343e+00, -1.4429e+00,\n",
              "       -6.9119e+00, -2.6114e+00, -5.9757e-01,  3.7847e-01,  6.3187e+00,\n",
              "        2.8965e+00, -2.5397e+00,  1.8022e+00,  3.5486e+00,  4.4721e+00,\n",
              "       -4.8481e+00, -3.6252e+00,  4.0969e+00, -2.0081e+00, -2.0122e-01,\n",
              "        2.5244e+00, -6.8817e-01,  6.7184e-01, -7.0466e+00,  1.6641e+00,\n",
              "       -2.2308e+00, -3.8960e+00,  6.1320e+00, -8.0335e+00, -1.7130e+00,\n",
              "        2.5688e+00, -5.2547e+00,  6.9845e+00,  2.7835e-01, -6.4554e+00,\n",
              "       -2.1327e+00, -5.6515e+00,  1.1174e+01, -8.0568e+00,  5.7985e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHWCqKcl55TY"
      },
      "source": [
        "## **Cosine similarity**\n",
        "\n",
        "**Cosine similarity** is a common way of assessing similarity between words in NLP. It is essentially defined as the cosine of the angle between the vectors representing the words of interest.\n",
        "\n",
        "Recall that the angle $\\phi$ between two non-zero vectors $u$ and $v$ can be computed as follows:\n",
        "\n",
        "$cos(\\phi) = \\frac{(u,v)}{||u||\\cdot||v||}$\n",
        "\n",
        "![](https://miro.medium.com/max/1394/1*_Bf9goaALQrS_0XkBozEiQ.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoi6FvPgMWid"
      },
      "source": [
        "Define a function computing cosine similarity between two vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpJS01dmvGbe"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine(v1, v2):\n",
        "  dot = np.dot(v1, v2)\n",
        "  return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEwtAXJRMc-s"
      },
      "source": [
        "Test your function by computing similarities of some random pairs of words, e.g. $dog$ and $puppy$ vs. $dog$ and $kitten$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RBooDbGvYOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006faf1c-f62b-4dfd-9bf5-2d756a6d1b9c"
      },
      "source": [
        "cosine(nlp('dog').vector, nlp('kitten').vector)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6515032"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgHDwfx8Mu66"
      },
      "source": [
        "## **Loading the text**\n",
        "\n",
        "Let's load the full text of *Alice in Wonderland*. It will serve us as a corpus of English words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am8NoIl2zMXi"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Alice in Wonderland\n",
        "response = requests.get('https://www.gutenberg.org/files/11/11-0.txt')\n",
        "\n",
        "# If you prefer Dracula, load this instead:\n",
        "# response = requests.get('https://www.gutenberg.org/cache/epub/345/pg345.txt')\n",
        "\n",
        "# Extracting separate words from the text\n",
        "doc = nlp(response.text)\n",
        "tokens = list(set([w.text for w in doc if w.is_alpha]))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAwABf4nNNR3"
      },
      "source": [
        "Check out the content of $\\texttt{tokens}$ now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4B4FRR6NRzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d27ad53-5622-4948-ff78-4d37bd5e00c5"
      },
      "source": [
        "tokens"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['confidence',\n",
              " 'OR',\n",
              " 'Straightway',\n",
              " 'INTERVIEWER',\n",
              " 'oblivious',\n",
              " 'dinner',\n",
              " 'picturesque',\n",
              " 'bigger',\n",
              " 'wrong',\n",
              " 'differ',\n",
              " 'kinks',\n",
              " 'material',\n",
              " 'Red',\n",
              " 'win',\n",
              " 'peered',\n",
              " 'tough',\n",
              " 'gentleness',\n",
              " 'silver',\n",
              " 'opponent',\n",
              " 'during',\n",
              " 'saddest',\n",
              " 'Face',\n",
              " 'drawn',\n",
              " 'mayhap',\n",
              " 'principle',\n",
              " 'inquiries',\n",
              " 'livin',\n",
              " 'Transcendentalism',\n",
              " 'seventeenth',\n",
              " 'Admiralty',\n",
              " 'Soh',\n",
              " 'pg',\n",
              " 'panting',\n",
              " 'appliances',\n",
              " 'latched',\n",
              " 'west',\n",
              " 'pollution',\n",
              " 'renewing',\n",
              " 'bush',\n",
              " 'paralysed',\n",
              " 'leather',\n",
              " 'horse',\n",
              " 'woman',\n",
              " 'Alone',\n",
              " 'plucked',\n",
              " 'visible',\n",
              " 'eatin',\n",
              " 'specific',\n",
              " 'knives',\n",
              " 'gable',\n",
              " 'even',\n",
              " 'immediate',\n",
              " 'fluttering',\n",
              " 'forestall',\n",
              " 'clutching',\n",
              " 'Transylvania',\n",
              " 'unmoved',\n",
              " 'stealing',\n",
              " 'sulky',\n",
              " 'fastnesses',\n",
              " 'robin',\n",
              " 'combination',\n",
              " 'snarled',\n",
              " 'suitability',\n",
              " 'shadder',\n",
              " 'voyage',\n",
              " 'steersman',\n",
              " 'suspicion',\n",
              " 'despatched',\n",
              " 'wing',\n",
              " 'explained',\n",
              " 'agonising',\n",
              " 'nigh',\n",
              " 'comic',\n",
              " 'needful',\n",
              " 'Churchman',\n",
              " 'blow',\n",
              " 'crying',\n",
              " 'discreetly',\n",
              " 'green',\n",
              " 'Second',\n",
              " 'rank',\n",
              " 'tennis',\n",
              " 'notwithstanding',\n",
              " 'owns',\n",
              " 'ascertain',\n",
              " 'Blue',\n",
              " 'vent',\n",
              " 'galloping',\n",
              " 'receipt',\n",
              " 'reverence',\n",
              " 'Hospital',\n",
              " 'Carfax',\n",
              " 'shrouded',\n",
              " 'chill',\n",
              " 'rubbed',\n",
              " 'sap',\n",
              " 'Have',\n",
              " 'hair',\n",
              " 'leapt',\n",
              " 'son',\n",
              " 'dwellers',\n",
              " 'Diary',\n",
              " 'Oriental',\n",
              " 'shrank',\n",
              " 'allow',\n",
              " 'provisions',\n",
              " 'merchant',\n",
              " 'swords',\n",
              " 'sprout',\n",
              " 'kindness',\n",
              " 'file',\n",
              " 'HENNESSEY',\n",
              " 'nuisance',\n",
              " 'would',\n",
              " 'run',\n",
              " 'suavely',\n",
              " 'interminable',\n",
              " 'reservations',\n",
              " 'onwards',\n",
              " 'suggest',\n",
              " 'peculiarly',\n",
              " 'twined',\n",
              " 'harvest',\n",
              " 'confines',\n",
              " 'singing',\n",
              " 'phonetic',\n",
              " 'courteous',\n",
              " 'hoarsely',\n",
              " 'offers',\n",
              " 'Look',\n",
              " 'Hungarian',\n",
              " 'frontier',\n",
              " 'speaks',\n",
              " 'weeps',\n",
              " 'secretary',\n",
              " 'suspected',\n",
              " 'emerge',\n",
              " 'steadier',\n",
              " 'lap',\n",
              " 'neutral',\n",
              " 'Thus',\n",
              " 'bent',\n",
              " 'mould',\n",
              " 'efforts',\n",
              " 'warlike',\n",
              " 'strain',\n",
              " 'fog',\n",
              " 'snatch',\n",
              " 'usin',\n",
              " 'fading',\n",
              " 'centaur',\n",
              " 'costliest',\n",
              " 'manifest',\n",
              " 'fabulous',\n",
              " 'Professor',\n",
              " 'refuges',\n",
              " 'watches',\n",
              " 'same',\n",
              " 'Release',\n",
              " 'propose',\n",
              " 'imperfect',\n",
              " 'rounds',\n",
              " 'warm',\n",
              " 'instinctively',\n",
              " 'wretch',\n",
              " 'flask',\n",
              " 'forbids',\n",
              " 'whispered',\n",
              " 'music',\n",
              " 'Sure',\n",
              " 'posted',\n",
              " 'frantic',\n",
              " 'sale',\n",
              " 'view',\n",
              " 'perspiration',\n",
              " 'replenished',\n",
              " 'condition',\n",
              " 'spider',\n",
              " 'sullen',\n",
              " 'similarly',\n",
              " 'WAY',\n",
              " 'becomes',\n",
              " 'swelled',\n",
              " 'painted',\n",
              " 'agone',\n",
              " 'continuous',\n",
              " 'battle',\n",
              " 'licking',\n",
              " 'stamp',\n",
              " 'crisp',\n",
              " 'forethought',\n",
              " 'playful',\n",
              " 'reet',\n",
              " 'fishermen',\n",
              " 'wilderness',\n",
              " 'wery',\n",
              " 'Olgaren',\n",
              " 'demoralised',\n",
              " 'gale',\n",
              " 'join',\n",
              " 'fool',\n",
              " 'worse',\n",
              " 'Himmel',\n",
              " 'Believe',\n",
              " 'Unless',\n",
              " 'withdraw',\n",
              " 'resurrection',\n",
              " 'deadly',\n",
              " 'though',\n",
              " 'Bethnal',\n",
              " 'drenched',\n",
              " 'witches',\n",
              " 'heroic',\n",
              " 'swiftly',\n",
              " 'puts',\n",
              " 'frisked',\n",
              " 'immortal',\n",
              " 'XIV',\n",
              " 'hours',\n",
              " 'murders',\n",
              " 'fire',\n",
              " 'maelstrom',\n",
              " 'go',\n",
              " 'harrowing',\n",
              " 'aftest',\n",
              " 'granted',\n",
              " 'violate',\n",
              " 'excite',\n",
              " 'tables',\n",
              " 'spoken',\n",
              " 'understanding',\n",
              " 'bride',\n",
              " 'pulpits',\n",
              " 'sorrowing',\n",
              " 'survived',\n",
              " 'suspicious',\n",
              " 'lintels',\n",
              " 'nailed',\n",
              " 'punished',\n",
              " 'mighty',\n",
              " 'on',\n",
              " 'met',\n",
              " 'Americanism',\n",
              " 'before',\n",
              " 'coffins',\n",
              " 'chat',\n",
              " 'unmask',\n",
              " 'weep',\n",
              " 'Matapan',\n",
              " 'imagined',\n",
              " 'boy',\n",
              " 'Leeds',\n",
              " 'derelict',\n",
              " 'purifying',\n",
              " 'achieve',\n",
              " 'BUT',\n",
              " 'centripetal',\n",
              " 'remind',\n",
              " 'approaching',\n",
              " 'devoted',\n",
              " 'permit',\n",
              " 'infect',\n",
              " 'COURT',\n",
              " 'card',\n",
              " 'build',\n",
              " 'rigidly',\n",
              " 'offer',\n",
              " 'slipped',\n",
              " 'psychic',\n",
              " 'battlements',\n",
              " 'stoppages',\n",
              " 'orders',\n",
              " 'Father',\n",
              " 'sorrow',\n",
              " 'embryo',\n",
              " 'napped',\n",
              " 'fit',\n",
              " 'slide',\n",
              " 'unloaded',\n",
              " 'risen',\n",
              " 'curtains',\n",
              " 'trifling',\n",
              " 'Survey',\n",
              " 'most',\n",
              " 'languid',\n",
              " 'bolder',\n",
              " 'Danes',\n",
              " 'walkin',\n",
              " 'incoherent',\n",
              " 'wander',\n",
              " 'invader',\n",
              " 'emerald',\n",
              " 'weighing',\n",
              " 'Winter',\n",
              " 'federal',\n",
              " 'alarms',\n",
              " 'catalog',\n",
              " 'agree',\n",
              " 'leper',\n",
              " 'Terrace',\n",
              " 'Cszeks',\n",
              " 'sudden',\n",
              " 'legend',\n",
              " 'solved',\n",
              " 'morbidly',\n",
              " 'gleams',\n",
              " 'tip',\n",
              " 'dividing',\n",
              " 'gathered',\n",
              " 'Secondly',\n",
              " 'literally',\n",
              " 'accepting',\n",
              " 'soldering',\n",
              " 'soberly',\n",
              " 'dreams',\n",
              " 'Kensington',\n",
              " 'watchers',\n",
              " 'till',\n",
              " 'Crucifix',\n",
              " 'Were',\n",
              " 'sooner',\n",
              " 'satiate',\n",
              " 'damaged',\n",
              " 'assertion',\n",
              " 'waving',\n",
              " 'bans',\n",
              " 'drawing',\n",
              " 'WOLF',\n",
              " 'hated',\n",
              " 'beamed',\n",
              " 'sofas',\n",
              " 'editions',\n",
              " 'ruffled',\n",
              " 'sheath',\n",
              " 'simplify',\n",
              " 'proposal',\n",
              " 'sorrowin',\n",
              " 'fill',\n",
              " 'base',\n",
              " 'passages',\n",
              " 'watched',\n",
              " 'craning',\n",
              " 'tinkle',\n",
              " 'types',\n",
              " 'softness',\n",
              " 'tolerably',\n",
              " 'concentrated',\n",
              " 'empiric',\n",
              " 'rifles',\n",
              " 'distorted',\n",
              " 'knowledge',\n",
              " 'herb',\n",
              " 'decoction',\n",
              " 'ones',\n",
              " 'Thames',\n",
              " 'descendants',\n",
              " 'Nights',\n",
              " 'hinderin',\n",
              " 'hallucination',\n",
              " 'redistribution',\n",
              " 'prettily',\n",
              " 'ADVENTURE',\n",
              " 'amount',\n",
              " 'differentiate',\n",
              " 'horseshoe',\n",
              " 'manifestations',\n",
              " 'Danube',\n",
              " 'overwork',\n",
              " 'imploring',\n",
              " 'Bartel',\n",
              " 'stone',\n",
              " 'customary',\n",
              " 'suffocate',\n",
              " 'grandfather',\n",
              " 'examination',\n",
              " 'rosary',\n",
              " 'far',\n",
              " 'mine',\n",
              " 'deign',\n",
              " 'exploring',\n",
              " 'sandy',\n",
              " 'marble',\n",
              " 'yelpin',\n",
              " 'movement',\n",
              " 'indexy',\n",
              " 'parried',\n",
              " 'pain',\n",
              " 'sheepskin',\n",
              " 'avarice',\n",
              " 'lead',\n",
              " 'Moreover',\n",
              " 'permitted',\n",
              " 'sticking',\n",
              " 'sails',\n",
              " 'doctrine',\n",
              " 'morrow',\n",
              " 'foes',\n",
              " 'waiting',\n",
              " 'tells',\n",
              " 'heap',\n",
              " 'cheerfulness',\n",
              " 'Englishman',\n",
              " 'Icelander',\n",
              " 'Looking',\n",
              " 'stertorous',\n",
              " 'transform',\n",
              " 'ancient',\n",
              " 'destroy',\n",
              " 'Everything',\n",
              " 'Pro',\n",
              " 'crevices',\n",
              " 'borne',\n",
              " 'eastern',\n",
              " 'violent',\n",
              " 'Striking',\n",
              " 'spiritually',\n",
              " 'remark',\n",
              " 'waited',\n",
              " 'auspices',\n",
              " 'Things',\n",
              " 'crystal',\n",
              " 'banished',\n",
              " 'scratch',\n",
              " 'soldiers',\n",
              " 'Turks',\n",
              " 'pall',\n",
              " 'desolation',\n",
              " 'under',\n",
              " 'be',\n",
              " 'possibilities',\n",
              " 'bogles',\n",
              " 'quicken',\n",
              " 'overtaken',\n",
              " 'tail',\n",
              " 'Rats',\n",
              " 'doesn',\n",
              " 'demons',\n",
              " 'tenth',\n",
              " 'expeckit',\n",
              " 'Interview',\n",
              " 'where',\n",
              " 'animile',\n",
              " 'loopholes',\n",
              " 'bestow',\n",
              " 'DETECTIVE',\n",
              " 'BILLINGTON',\n",
              " 'broken',\n",
              " 'contortions',\n",
              " 'implicitly',\n",
              " 'Wallachs',\n",
              " 'infer',\n",
              " 'mistress',\n",
              " 'refused',\n",
              " 'diabolical',\n",
              " 'belongs',\n",
              " 'inflicts',\n",
              " 'sickened',\n",
              " 'charges',\n",
              " 'badly',\n",
              " 'Doubtless',\n",
              " 'interrogatively',\n",
              " 'stinted',\n",
              " 'require',\n",
              " 'wantonness',\n",
              " 'drew',\n",
              " 'gloated',\n",
              " 'stench',\n",
              " 'formats',\n",
              " 'smile',\n",
              " 'ark',\n",
              " 'ajar',\n",
              " 'matches',\n",
              " 'Title',\n",
              " 'ever',\n",
              " 'hopes',\n",
              " 'food',\n",
              " 'rocky',\n",
              " 'life',\n",
              " 'possibly',\n",
              " 'blinked',\n",
              " 'bleeding',\n",
              " 'metaphysician',\n",
              " 'estimate',\n",
              " 'NOTICE',\n",
              " 'improper',\n",
              " 'belt',\n",
              " 'smattering',\n",
              " 'V',\n",
              " 'why',\n",
              " 'bacca',\n",
              " 'main',\n",
              " 'lady',\n",
              " 'draught',\n",
              " 'dictation',\n",
              " 'chiefest',\n",
              " 'sullenness',\n",
              " 'dearest',\n",
              " 'honestly',\n",
              " 'criminal',\n",
              " 'effective',\n",
              " 'alley',\n",
              " 'comically',\n",
              " 'tower',\n",
              " 'slighted',\n",
              " 'Raised',\n",
              " 'sword',\n",
              " 'choking',\n",
              " 'authorities',\n",
              " 'abated',\n",
              " 'outcast',\n",
              " 'octroi',\n",
              " 'forced',\n",
              " 'eleventh',\n",
              " 'gases',\n",
              " 'formed',\n",
              " 'ouse',\n",
              " 'perched',\n",
              " 'While',\n",
              " 'records',\n",
              " 'shoals',\n",
              " 'judgment',\n",
              " 'driving',\n",
              " 'extending',\n",
              " 'artificial',\n",
              " 'manias',\n",
              " 'ANYTHING',\n",
              " 'sovereign',\n",
              " 'partly',\n",
              " 'forbid',\n",
              " 'Get',\n",
              " 'edges',\n",
              " 'cheek',\n",
              " 'placed',\n",
              " 'appalling',\n",
              " 'bluff',\n",
              " 'Expected',\n",
              " 'gang',\n",
              " 'span',\n",
              " 'echoed',\n",
              " 'denial',\n",
              " 'hysterical',\n",
              " 'unutterable',\n",
              " 'Young',\n",
              " 'listened',\n",
              " 'walking',\n",
              " 'calmness',\n",
              " 'wring',\n",
              " 'boot',\n",
              " 'typewriting',\n",
              " 'deer',\n",
              " 'autopsy',\n",
              " 'produced',\n",
              " 'youthful',\n",
              " 'heaviness',\n",
              " 'panes',\n",
              " 'bristles',\n",
              " 'steam',\n",
              " 'breaking',\n",
              " 'delusion',\n",
              " 'silence',\n",
              " 'Rushed',\n",
              " 'Present',\n",
              " 'deed',\n",
              " 'breakfast',\n",
              " 'Yard',\n",
              " 'Away',\n",
              " 'intact',\n",
              " 'spirited',\n",
              " 'contented',\n",
              " 'paths',\n",
              " 'wondrous',\n",
              " 'Dinner',\n",
              " 'flower',\n",
              " 'mornin',\n",
              " 'vault',\n",
              " 'tryin',\n",
              " 'Amen',\n",
              " 'apprenticed',\n",
              " 'palsy',\n",
              " 'gaol',\n",
              " 'criminals',\n",
              " 'bravely',\n",
              " 'rarer',\n",
              " 'redress',\n",
              " 'getting',\n",
              " 'lack',\n",
              " 'invent',\n",
              " 'Amongst',\n",
              " 'buffeting',\n",
              " 'employed',\n",
              " 'dry',\n",
              " 'bygone',\n",
              " 'thrill',\n",
              " 'thinks',\n",
              " 'patronymic',\n",
              " 'contain',\n",
              " 'swiftness',\n",
              " 'flour',\n",
              " 'MEN',\n",
              " 'clients',\n",
              " 'aback',\n",
              " 'wrought',\n",
              " 'Solicitor',\n",
              " 'void',\n",
              " 'satisfactorily',\n",
              " 'piercingly',\n",
              " 'lad',\n",
              " 'fatalities',\n",
              " 'fact',\n",
              " 'sleepy',\n",
              " 'pleasure',\n",
              " 'stopping',\n",
              " 'visiting',\n",
              " 'Purfleet',\n",
              " 'yelling',\n",
              " 'airt',\n",
              " 'individuals',\n",
              " 'rebuff',\n",
              " 'owling',\n",
              " 'deil',\n",
              " 'Notwithstanding',\n",
              " 'Regaining',\n",
              " 'trial',\n",
              " 'smallest',\n",
              " 'tiniest',\n",
              " 'illumine',\n",
              " 'redeeming',\n",
              " 'traffic',\n",
              " 'swooned',\n",
              " 'Despite',\n",
              " 'insensibility',\n",
              " 'wars',\n",
              " 'contingent',\n",
              " 'materialise',\n",
              " 'natural',\n",
              " 'righteousness',\n",
              " 'blessed',\n",
              " 'unthinkingly',\n",
              " 'Potter',\n",
              " 'reduction',\n",
              " 'Seventy',\n",
              " 'kick',\n",
              " 'earthly',\n",
              " 'sequel',\n",
              " 'c',\n",
              " 'cuts',\n",
              " 'tethered',\n",
              " 'inch',\n",
              " 'seemed',\n",
              " 'cawing',\n",
              " 'wider',\n",
              " 'capture',\n",
              " 'Antwerp',\n",
              " 'operations',\n",
              " 'rose',\n",
              " 'oppose',\n",
              " 'silent',\n",
              " 'Yorkshire',\n",
              " 'Morpheus',\n",
              " 'hat',\n",
              " 'tide',\n",
              " 'confer',\n",
              " 'whatever',\n",
              " 'arouse',\n",
              " 'worship',\n",
              " 'complete',\n",
              " 'Wharf',\n",
              " 'limitations',\n",
              " 'phase',\n",
              " 'Ville',\n",
              " 'sheer',\n",
              " 'focus',\n",
              " 'smarts',\n",
              " 'in',\n",
              " 'revenge',\n",
              " 'devouring',\n",
              " 'creep',\n",
              " 'tricks',\n",
              " 'fitted',\n",
              " 'stretched',\n",
              " 'fleeting',\n",
              " 'cabs',\n",
              " 'dreadful',\n",
              " 'gentleman',\n",
              " 'westward',\n",
              " 'defibrinate',\n",
              " 'show',\n",
              " 'yarns',\n",
              " 'viewed',\n",
              " 'leave',\n",
              " 'sea',\n",
              " 'foolish',\n",
              " 'MS',\n",
              " 'foremost',\n",
              " 'growling',\n",
              " 'physiognomist',\n",
              " 'Szekelys',\n",
              " 'spy',\n",
              " 'halted',\n",
              " 'harm',\n",
              " 'y',\n",
              " 'Strange',\n",
              " 'Billreuth',\n",
              " 'archway',\n",
              " 'remembrance',\n",
              " 'entitled',\n",
              " 'lunch',\n",
              " 'stertorously',\n",
              " 'Brave',\n",
              " 'besides',\n",
              " 'fury',\n",
              " 'consent',\n",
              " 'Shut',\n",
              " 'hiss',\n",
              " 'library',\n",
              " 'crouched',\n",
              " 'restraining',\n",
              " 'broaden',\n",
              " 'licked',\n",
              " 'nurse',\n",
              " 'speed',\n",
              " 'From',\n",
              " 'ordered',\n",
              " 'let',\n",
              " 'dismay',\n",
              " 'millions',\n",
              " 'joining',\n",
              " 'stragglers',\n",
              " 'soothing',\n",
              " 'whithersoever',\n",
              " 'assume',\n",
              " 'Sister',\n",
              " 'look',\n",
              " 'fur',\n",
              " 'rigid',\n",
              " 'name',\n",
              " 'grab',\n",
              " 'befooling',\n",
              " 'solder',\n",
              " 'gold',\n",
              " 'noise',\n",
              " 'rug',\n",
              " 'earthy',\n",
              " 'Road',\n",
              " 'fluffy',\n",
              " 'naturally',\n",
              " 'pieces',\n",
              " 'sped',\n",
              " 'agitation',\n",
              " 'imperious',\n",
              " 'fulfilled',\n",
              " 'boon',\n",
              " 'interpreting',\n",
              " 'urged',\n",
              " 'uncertain',\n",
              " 'retired',\n",
              " 'centres',\n",
              " 'beside',\n",
              " 'promises',\n",
              " 'youth',\n",
              " 'queer',\n",
              " 'comes',\n",
              " 'anxiety',\n",
              " 'caverns',\n",
              " 'lookin',\n",
              " 'wo',\n",
              " 'incredible',\n",
              " 'empowered',\n",
              " 'afresh',\n",
              " 'reverse',\n",
              " 'afflict',\n",
              " 'back',\n",
              " 'withdrew',\n",
              " 'vessel',\n",
              " 'Defects',\n",
              " 'aids',\n",
              " 'hesitatingly',\n",
              " 'poles',\n",
              " 'ACTUAL',\n",
              " 'bitterly',\n",
              " 'accuracy',\n",
              " 'studded',\n",
              " 'disobeying',\n",
              " 'Holland',\n",
              " 'fellow',\n",
              " 'consulting',\n",
              " 'fiancée',\n",
              " 'mention',\n",
              " 'welled',\n",
              " 'theory',\n",
              " 'devilish',\n",
              " 'dictionary',\n",
              " 'gnawing',\n",
              " 'afeard',\n",
              " 'sawed',\n",
              " 'mark',\n",
              " 'enjoyed',\n",
              " 'assembled',\n",
              " 'unscrew',\n",
              " 'connected',\n",
              " 'towered',\n",
              " 'darknesses',\n",
              " 'PROVIDED',\n",
              " 'skywards',\n",
              " 'sail',\n",
              " 'wrapping',\n",
              " 'conscience',\n",
              " 'after',\n",
              " 'Despises',\n",
              " 'Scotland',\n",
              " 'foreman',\n",
              " 'bargaining',\n",
              " 'ANNEXATION',\n",
              " 'Ugric',\n",
              " 'crumbled',\n",
              " 'revolted',\n",
              " 'impatient',\n",
              " 'gladder',\n",
              " 'protectingly',\n",
              " 'impassiveness',\n",
              " 'afar',\n",
              " 'Sir',\n",
              " 'secondly',\n",
              " 'reflect',\n",
              " 'beginnin',\n",
              " 'unstained',\n",
              " 'Romanoffs',\n",
              " 'laneway',\n",
              " 'ownership',\n",
              " 'Host',\n",
              " 'Robin',\n",
              " 'cessation',\n",
              " 'CONTRACT',\n",
              " 'law',\n",
              " 'Strasba',\n",
              " 'hobby',\n",
              " 'waist',\n",
              " 'hup',\n",
              " 'employer',\n",
              " 'tale',\n",
              " 'changed',\n",
              " 'odium',\n",
              " 'surely',\n",
              " 'assurance',\n",
              " 'slacken',\n",
              " 'triumphant',\n",
              " 'reserved',\n",
              " 'patrolled',\n",
              " 'distributed',\n",
              " 'argues',\n",
              " 'snap',\n",
              " 'display',\n",
              " 'hills',\n",
              " 'alive',\n",
              " 'rag',\n",
              " 'Wrapper',\n",
              " 'hobbled',\n",
              " 'origin',\n",
              " 'unutterably',\n",
              " 'practitioner',\n",
              " 'Stay',\n",
              " 'chicken',\n",
              " 'bushy',\n",
              " 'armaments',\n",
              " 'vigil',\n",
              " 'proverbs',\n",
              " 'rats',\n",
              " 'coroner',\n",
              " 'designs',\n",
              " 'sheets',\n",
              " 'forgits',\n",
              " 'refuse',\n",
              " 'entailed',\n",
              " 'reading',\n",
              " 'moth',\n",
              " 'consequently',\n",
              " 'Huns',\n",
              " 'beetling',\n",
              " 'treat',\n",
              " 'whistled',\n",
              " 'clasped',\n",
              " 'sanest',\n",
              " 'gladsome',\n",
              " 'winds',\n",
              " 'whenever',\n",
              " 'smoked',\n",
              " 'prominently',\n",
              " 'Carpathian',\n",
              " 'chinks',\n",
              " 'inheritors',\n",
              " 'image',\n",
              " 'consumed',\n",
              " 'slope',\n",
              " 'weeks',\n",
              " 'fishing',\n",
              " 'tremulous',\n",
              " 'vague',\n",
              " 'sexton',\n",
              " 'yourself',\n",
              " 'horrify',\n",
              " 'fondly',\n",
              " 'nerved',\n",
              " 'malignity',\n",
              " 'parallel',\n",
              " 'unvaried',\n",
              " 'barometrical',\n",
              " 'moonrise',\n",
              " 'Council',\n",
              " 'reeled',\n",
              " 'profanation',\n",
              " 'Thing',\n",
              " 'crow',\n",
              " 'hysterics',\n",
              " 'digression',\n",
              " 'foreknowledge',\n",
              " 'meet',\n",
              " 'unseat',\n",
              " 'exempt',\n",
              " 'stress',\n",
              " 'woeful',\n",
              " 'troubles',\n",
              " 'resolution',\n",
              " 'token',\n",
              " 'usually',\n",
              " 'scale',\n",
              " 'Edward',\n",
              " 'Charcot',\n",
              " 'pushing',\n",
              " 'brute',\n",
              " 'Consulate',\n",
              " 'outside',\n",
              " 'dragged',\n",
              " 'keys',\n",
              " 'beneath',\n",
              " 'accomplished',\n",
              " 'Piccadilly',\n",
              " 'flagged',\n",
              " 'ruin',\n",
              " 'nationality',\n",
              " 'preparations',\n",
              " 'basely',\n",
              " 'sincerely',\n",
              " 'gaslight',\n",
              " 'clock',\n",
              " 'interruption',\n",
              " 'practical',\n",
              " 'when',\n",
              " 'sha',\n",
              " 'lawn',\n",
              " 'greens',\n",
              " 'calmly',\n",
              " 'uncanny',\n",
              " 'glories',\n",
              " 'funeral',\n",
              " 'sorting',\n",
              " 'privilege',\n",
              " 'collection',\n",
              " 'penetrate',\n",
              " 'compare',\n",
              " 'cheerily',\n",
              " 'bog',\n",
              " 'protested',\n",
              " 'nought',\n",
              " 'Magyar',\n",
              " 'relying',\n",
              " 'town',\n",
              " 'Underground',\n",
              " 'pat',\n",
              " 'thoroughly',\n",
              " 'Hawkins',\n",
              " 'regulations',\n",
              " 'facto',\n",
              " 'severed',\n",
              " 'blotted',\n",
              " 'abbey',\n",
              " 'masonry',\n",
              " 'pacify',\n",
              " 'brooked',\n",
              " 'philosophically',\n",
              " 'odd',\n",
              " 'beforehand',\n",
              " 'fight',\n",
              " 'nails',\n",
              " 'shiverin',\n",
              " 'Marquesas',\n",
              " 'recoil',\n",
              " 'truism',\n",
              " 'Salvation',\n",
              " 'ballet',\n",
              " 'trailing',\n",
              " 'Henceforth',\n",
              " 'crashing',\n",
              " 'begins',\n",
              " 'email',\n",
              " 'sided',\n",
              " 'vain',\n",
              " 'blinds',\n",
              " 'latest',\n",
              " 'companions',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GfkThRpNUKL"
      },
      "source": [
        "Define a function that takes a word and lists the $n$ most similar words in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT_h-7n50kia"
      },
      "source": [
        "def spacy_closest(tokens, new_vec, n=10):\n",
        "  return sorted(tokens, key=lambda t: cosine(nlp(t).vector, new_vec), reverse=True)[:n]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLEiz9UNjrO"
      },
      "source": [
        "Try to find words similar to some random words, e.g. $good$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1JL2VrF0ltD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35aebbc-4e76-43d4-9553-7c7d92e792bc"
      },
      "source": [
        "spacy_closest(tokens, nlp('good').vector)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b4ff7de011d5>:5: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['excellent',\n",
              " 'nice',\n",
              " 'pleasant',\n",
              " 'wise',\n",
              " 'happy',\n",
              " 'whatever',\n",
              " 'solid',\n",
              " 'hopeless',\n",
              " 'wrong',\n",
              " 'Because']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBZhjqSgNqNd"
      },
      "source": [
        "You can also get creative and search for combinations of words. For example, what is similar to $king - man + woman$?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKI4SrhMN-EV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8684a31-9479-4435-fa51-8d56b02c416f"
      },
      "source": [
        "print(spacy_closest(tokens, nlp('king').vector - nlp('man').vector + nlp('woman').vector))\n",
        "print(spacy_closest(tokens, nlp('Alice').vector - nlp('girl').vector + nlp('man').vector))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b4ff7de011d5>:5: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['king', 'throne', 'King', 'Queen', 'usurpation', 'respectable', 'ancient', 'accepting', 'considerable', 'contemptuously']\n",
            "['soldier', 'Edwin', 'William', 'Father', 'Carroll', 'woman', 'Edgar', 'David', 'Footman', 'he']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpD73pj8OGGt"
      },
      "source": [
        "## **Sentence vectors**\n",
        "\n",
        "We can also construct a vector representation for the whole sentence. For example, we can define it as an *average* of the   vectors representing the words in it.\n",
        "\n",
        "Let's take a random sentence *My favorite food is strawberry ice cream* and construct its vector representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5xr_3MkEPeM"
      },
      "source": [
        "sent = nlp('My favorite food is strawberry ice cream.')\n",
        "\n",
        "v_sum = sent[0].vector\n",
        "for w in sent[1:]:\n",
        "  v_sum += w.vector\n",
        "sentv = v_sum / len(sent)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMf_OllyOvfX"
      },
      "source": [
        "Let's also extract sentences (as opposed to individual words) from our corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jazUz0WvDsa3"
      },
      "source": [
        "sents = list(doc.sents)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzDdce7xO7QZ"
      },
      "source": [
        "Define a function that takes a random sentence and lists $n$ most similar sentences from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7pQe8xD1x0"
      },
      "source": [
        "def spacy_closest_sent(sentences, input_vec, n=10):\n",
        "  return sorted(sentences, key=lambda sent: cosine(sent.vector, input_vec), reverse=True)[:n]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6m06T18PDQ8"
      },
      "source": [
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkDCEWWwEzIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e738b8ae-5046-4875-905a-ed9c44663486"
      },
      "source": [
        "for s in spacy_closest_sent(sents, sentv, n=10):\n",
        "  print(s)\n",
        "  print('\\n---')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My notion was that you had been\r\n",
            "    (Before she had this fit)\r\n",
            "An obstacle that came between\r\n",
            "    Him, and ourselves, and it.\r\n",
            "\r\n",
            "\n",
            "\n",
            "---\n",
            "This\r\n",
            "is the driest thing I know.\n",
            "\n",
            "---\n",
            "And oh, my poor hands, how is it\n",
            "\n",
            "---\n",
            "beautiful Soup!\r\n",
            "Soup of the evening, beautiful Soup!\r\n",
            "    Beauâootiful Sooâoop!\r\n",
            "    \n",
            "\n",
            "---\n",
            "Oh\r\n",
            "my fur and whiskers!\n",
            "\n",
            "---\n",
            "âI dare say youâre wondering why I donât put my arm round your waist,â\r\n",
            "the Duchess said after a pause: âthe reason is, that Iâm doubtful about\r\n",
            "the temper of your flamingo.\n",
            "\n",
            "---\n",
            "The Mouse did not\r\n",
            "answer, so Alice went on eagerly: âThere is such a nice little dog near\r\n",
            "our house I should like to show you!\n",
            "\n",
            "---\n",
            "And sheâs such a capital one for catching mice you\r\n",
            "canât think!\n",
            "\n",
            "---\n",
            "Soup\r\n",
            "does very well withoutâMaybe itâs always pepper that makes people\r\n",
            "hot-tempered,â she went on, very much pleased at having found out a new\r\n",
            "kind of rule, âand vinegar that makes them sourâand camomile that makes\r\n",
            "them bitterâandâand barley-sugar and such things that make children\r\n",
            "sweet-tempered.\n",
            "\n",
            "---\n",
            "âCome, thereâs half my plan\r\n",
            "done now!\n",
            "\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b4ff7de011d5>:5: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VewB5XqkPLdx"
      },
      "source": [
        "## **References**\n",
        "\n",
        "This notebook is inspired by a [tutorial by Allison Parrish](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469)."
      ]
    }
  ]
}